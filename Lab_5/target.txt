Распознавание рукописных цифр с помощью
нейронной сети
В этой работе необходимо реализовать нейронную сеть прямого
распространения для распознавания рукописных цифр. Обучение
нейросети уже выполнено, поэтому следует использовать уже
рассчитанные параметры модели. В процессе выполнения работы нужно
реализовать алгоритм расчета значения сети, используя эти параметры
для определения того, какая цифра изображена.
Введение в нейронные сети
Нейронная сеть представляет собой сеть, состоящую из соединенных между собой нескольких
нейронов. Каждый нейрон можно представить простой моделью:
Рисунок 1 Нейрон
Нейрон состоит из нескольких входов – дендритов, тела нейрона и одного выхода – аксона. Значение
выхода можно однозначно рассчитать из входов, используя параметры 𝜃 – весовые коэффициенты,
соединяющие дендриты с телом нейрона. Значение рассчитывается с помощью функции 𝑔 𝑧 под
названием сигмоид, используемой также в логистической регрессии и методе опорных векторов.
В общем виде:
𝑔 𝑧 =1
1 + 𝑒 −𝑧
ℎ𝜃 𝑥 =1
1 + 𝑒 −𝜃𝑥
Или для нейрона:
Здесь 𝜃 – весовые коэффициенты (параметры модели).
𝑥 – значения на входах нейрона.
На рисунке 2 приведен возможный вариант нейросети.Рисунок 2 Пример простой нейронной сети
Эта сеть состоит из 3 слоев. Первый слой – входной. Состоит из трех нейронов. Второй слой – скрытый.
Состоит так же из трех нейронов. Последний слой выходной, состоит из одного единственного нейрона.
В случае многоклассовой классификации, как в данной лабораторной работе, в выходном слое может
быть несколько нейронов по числу распознаваемых классов.
Сеть прямого распространения (Feedforward)
Нейронная сеть, в которой все связи направлены строго от входных нейронов к выходным, называется
сетью прямого распространения (Feedforward). Именно этот вид нейронной сети рассматривается в
лабораторной работе. Также такую сеть называют многослойным персептроном (MLP – Multi-Layer
Perceptron).
Рассмотрим порядок расчета выходного значения сети по известным значениям входов и параметрам.
Рисунок 3 Расчет значения нейросети
На каждом слое нейросети (кроме последнего) добавляется по одному нейрону (𝑥0 и 𝑎02 ), значения
которых равны +1. Эти нейроны нужны для того, чтобы возможно было использовать векторизацию
вычислений для расчета выходного значения сети.
Для того, чтобы вычислить значение нейрона 𝑎12
воспользоваться формулой:
со второго слоя (см. рисунок 3), нужно
𝑎12 = 𝑔 𝜃101 𝑥0 + 𝜃111 𝑥1 + 𝜃121 𝑥2 + 𝜃131 𝑥3
Здесь применяется сигмоид 𝑔 𝑧 . А в качестве параметра – сумма значений входов, поэлементно
перемноженных на параметры модели.Аналогично можно рассчитать значения на выходе остальных нейронов второго слоя сети:
𝑎22 = 𝑔 𝜃201 𝑥0 + 𝜃211 𝑥1 + 𝜃221 𝑥2 + 𝜃231 𝑥3
𝑎32 = 𝑔 𝜃301 𝑥0 + 𝜃311 𝑥1 + 𝜃321 𝑥2 + 𝜃331 𝑥3
Рисунок 4 поясняет суть индексов в этих формулах:
Рисунок 4 Пояснение к индексам в формуле
Используя тот же подход, можно рассчитать и значение на выходе нейросети. Оно будет вычисляться по
формуле:
ℎ𝜃 𝑥 = 𝑎13 = 𝑔 𝜃102 𝑎02 + 𝜃112 𝑎12 + 𝜃122 𝑎22 + 𝜃132 𝑎32
Векторная реализация расчета выхода нейронной сети
На практике чаще всего используют векторную (основанную на операциях с векторами и матрицами)
реализацию этого алгоритма. Векторная реализация проще и эффективнее с точки зрения
производительности, так как во многих языках существуют высокопроизводительные реализации
библиотек для матричных вычислений.
Рассмотрим набор уравнений для расчета значения нейросети, который был представлен выше:
𝑎12 = 𝑔 𝜃101 𝑥0 + 𝜃111 𝑥1 + 𝜃121 𝑥2 + 𝜃131 𝑥3
𝑎22 = 𝑔 𝜃201 𝑥0 + 𝜃211 𝑥1 + 𝜃221 𝑥2 + 𝜃231 𝑥3
𝑎32 = 𝑔 𝜃301 𝑥0 + 𝜃311 𝑥1 + 𝜃321 𝑥2 + 𝜃331 𝑥3
3
2
2
2
2
2
2
2
2
ℎ𝜃 𝑥 = 𝑎1 = 𝑔 𝜃10 𝑎0 + 𝜃11 𝑎1 + 𝜃12 𝑎2 + 𝜃13 𝑎3
Введем матрицу 𝜃 1 , которая описывает весовые коэффициенты для расчета значений слоя 2 из
входных значений слоя 1:
𝜃101𝜃111𝜃121𝜃131
𝜃 1 = 𝜃201𝜃211𝜃221𝜃231
𝜃301𝜃311𝜃321𝜃331
Тогда значения слоя 2 можно получить, перемножив значения матрицы 𝜃 1 на значения входного слоя
𝑥:
𝑎02 = 1
𝑎2 =
𝑎12
𝑎22
𝑎32
=𝑔
𝜃101𝜃111𝜃121𝜃13
𝜃201𝜃211𝜃221𝜃231
𝜃301𝜃311𝜃321𝜃331
=𝑔 𝜃 1 𝑥
1
𝑥0 = 1
𝑥1
×
𝑥2
𝑥3
1
1
1
1
𝜃10 𝑥0 + 𝜃11 𝑥1 + 𝜃12 𝑥2 + 𝜃13 𝑥3
=𝑔
𝜃201 𝑥0 + 𝜃211 𝑥1 + 𝜃221 𝑥2 + 𝜃231 𝑥3
𝜃301 𝑥0 + 𝜃311 𝑥1 + 𝜃321 𝑥2 + 𝜃331 𝑥3Если принять, что 𝑥 = 𝑎 1 , то можно записать 𝑎 2 = 𝑔 𝜃 1 𝑎 1 . Функция 𝑔 𝑧 применяется к каждому
элементу получившегося вектора.
С помощью формулы 𝑎 2 = 𝑔 𝜃 1 𝑎 1 можно вычислить значения на выходах нейронов второго слоя.
Аналогично можно рассчитать значения на выходе нейрона третьего слоя сети. Пусть у нас имеется
матрица 𝜃 2 , описывающая весовые коэффициенты для расчета слоя 3 из слоя 2:
𝜃 2 = 𝜃102
𝜃112
𝜃122
𝜃132
Тогда значение нейросети можно вычислить по формуле:
𝑎02
3
ℎ𝜃 𝑥 = 𝑎1 = 𝑎 3 = 𝑔
2
𝜃10
2
𝜃11
2
𝜃12
2
𝜃13 ×
𝑎12
2
𝑎2
𝑎32
= 𝑔 𝜃102 𝑎02 + 𝜃112 𝑎12 + 𝜃122 𝑎22 + 𝜃132 𝑎32
=𝑔 𝜃 2 𝑎2
Теперь, если собрать всё вместе:
ℎ𝜃 𝑥 = 𝑔 𝜃 2 𝑎 2
=𝑔 𝜃 2 𝑔 𝜃 1 𝑎1
Приведенная выше формула позволяет вычислить выход нейросети по известным входам 𝑥 и
параметрам 𝜃.
Внимание! При векторной реализации алгоритма важно помнить о добавлении нулевого нейрона со
значением +1 на всех слоях, кроме последнего.
Структура нейросети
На рисунке 5 изображена структура нейросети. Она состоит из входного слоя, скрытого слоя и
выходного слоя. Так как размер изображений цифр 20×20 точек, количество входных нейронов сети
равно 400 (не считая входа x0 с постоянным значением +1). Второй (скрытый) слой нейросети состоит из
25 нейронов. Последний выходной слой состоит из 10 нейронов по числу распознаваемых цифр – от 0
до 9.Рисунок 5 Структура нейронной сети распознавания цифр
Описание наборов данных
Тестовая выборка хранится в файле test_set.mat и состоит из 5000 рукописных цифр. Для загрузки
данных в скрипт используйте функцию scipy.io.loadmat с именем файла в качестве параметра. Будет
загружена матрица X и вектор y.
Матрица X представляет собой рукописные цифры. Она состоит из 5000 строк по числу тестовых
примеров и 400 столбцов по числу точек на изображении. Каждое изображение цифры имеет размеры
20×20 точек, отсюда 400 столбцов в матрице X.
Вектор y – это вектор-столбец, состоящий из 5000 элементов. Каждый элемент определяет класс
распознаваемой цифры. Цифре «0» соответствует класс 10, остальные классы соответствуют своим
цифрам.
Параметры обученной нейросети хранятся в файле weights.mat. Параметры представляют собой 2
матрицы – Theta1 и Theta2. В данной работе используется трёхслойная сеть, поэтому используются 2
матрицы параметров. Первая матрица содержит коэффициенты, связывающие первый и второй слои. Ее
размер 25×401 (25 строк и 401 столбец). Число строк соответствует числу нейронов во втором слое, а
число столбцов – числу нейронов в первом входном слое, плюс 1.
Аналогично матрица Theta2 содержит матрицу коэффициентов, связывающих второй слой с третьим.
Размер этой матрицы, исходя из количества нейронов во втором и третьем слоях, составляет 10×26.
𝑇ℎ𝑒𝑡𝑎1 =
1
𝜃1,01
𝜃1,1
1
𝜃2,01
1
𝜃2,1
… 𝜃2,400
⋮ ⋮ ⋮ ⋮
1
1
𝜃25,1
… 𝜃25,400
1
𝜃25,0
…
2
1
𝜃1,400
Разъяснение индексов см. на рисунке 4.
Порядок выполнения работы
1. Создать рабочее окружение
𝑇ℎ𝑒𝑡𝑎2 =
2
2
… 𝜃1,25
𝜃1,0𝜃1,1
2
𝜃2,02
2
𝜃2,1
… 𝜃2,25
⋮ ⋮ ⋮ ⋮
2
2
𝜃10,1
… 𝜃10,25
2
𝜃10,0Создать отдельный каталог для выполнения лабораторной работы и скопировать в него файлы с
расширениями .py и .mat из архива задания. Создать в каталоге файл run.py, в который будет
записываться код скрипта.
2. Добавить в скрипт код загрузки данных из файлов test_set.mat и weights.mat
Для загрузки данных из файлов .mat используется функция scipy.io.loadmat, которой передаётся имя
файла. Не забудьте подключить модуль scipy.io в начале вашего скрипта.
Из файла test_set.mat необходимо извлечь матрицу X по ключу ‘X’ и вектор-столбец y по ключу ‘y’. Из
файла weights.mat необходимо извлечь матрицы весовых коэффициентов Theta1 и Theta2 по ключам
‘Theta1’ и ‘Theta2’ соответственно.
Определите также параметр m, который должен равняться числу строк в матрице X.
3. Добавить код, выводящий на экран 100 случайных цифр из матрицы X
Для вывода случайных цифр на экран используется функция displayData из файла displayData.py.
Подключите её в начале вашего скрипта. В функцию displayData передаются примеры из матрицы X.
Чтобы выбрать случайным образом 100 примеров из матрицы X, сначала сгенерируйте индексы строк. С
помощью вызова функции numpy.random.permutation(m) получите массив индексов строк,
перемешанных случайным образом. Затем возьмите первые 100 элементов полученного массива и
используйте их как индексы примеров из матрицы X. Столбцы из матрицы X нужно брать все. Если всё
сделано правильно, должен получиться следующий рисунок:
4. Дополнить код функции sigmoid в файле sigmoid.py
В файле sigmoid.py написать реализацию функции sigmoid по формуле
1
1 + 𝑒 −𝑧
Следует помнить, что в качестве параметра z в функцию может быть передан вектор или матрица
произвольной размерности.
𝑔 𝑧 =
5. Реализовать вычисление отклика нейронной сети на входной пример
В файле predict.py реализовать вычисление отклика нейронной сети. При реализации нужно
использовать векторную форму: ℎ𝜃 𝑥 = 𝑔 𝜃 2 𝑎 2
=𝑔 𝜃 2 𝑔 𝜃1 𝑎1
.
Сначала необходимо определить количество примеров в матрице X. Количество примеров – это
количество строк в X.Затем необходимо добавить к матрице X единичный вектор-столбец. Он нужен для векторизации
вычислений. Для генерации вектора-столбца используйте функцию np.ones. Присоедините вектор-
столбец слева к матрице X, используя код ниже:
a1 = np.c_[ones, X]
Здесь ones – единичный вектор-столбец.
Вычислите значения на входах второго (скрытого) слоя нейросети (𝜃 1 𝑎 1 ). Для этого нужно
перемножить матрицу a1 на коэффициенты Theta1, связывающие 1 и 2 слой нейросети. Матрицу Theta1
необходимо транспонировать, чтобы перемножение выполнялось корректно. Для перемножения
матриц используйте функцию np.dot.
Вычислите значения на выходе второго слоя нейросети (𝑎 2 или 𝑔 𝜃 1 𝑎 1 ). Для этого примените
активационную функцию – 𝑔 (сигмоид) – к каждому элементу матрицы, полученной в результате
перемножения на предыдущем этапе. После этого добавьте единичный столбец к матрице.
Вычислите значения на выходе нейросети (ℎ𝜃 𝑥 ). Для этого перемножьте матрицу 𝑎 2 на
транспонированную матрицу коэффициентов Theta2 (𝜃 2 ) и примените к каждому элементу
полученной матрицы активационную функцию 𝑔 (сигмоид).
Если вы всё сделали правильно, гипотеза ℎ𝜃 𝑥 должна представлять собой матрицу из 5000 строк (по
числу тестовых примеров) и 10 столбцов (по числу распознаваемых цифр). Каждая строка матрицы
представляет собой 10 чисел в диапазоне от 0 до 1.
Номер тестового примера
Распознаваемая цифра
1234567891010,10,20,10,10,10,20,90,10,30,1«7»
20,90,10,10,20,10,10,20,30,10,1«1»
30,10,30,90,10,10,2...0,10,10,20,1«3»
50000,10,20,10,30,30,10,10,10,10,9«10»
Индекс максимального числа в строке даёт искомую цифру (см. рисунок выше). Например, для первого
примера максимальный отклик нейросети на 7 выходе (значение 0.9), значит для этого примера
нейросеть предсказала значение «7».
Определите цифры, которая распознала нейросеть. Для этого используйте функцию np.argmax. В
качестве дополнительного параметра укажите axis=1, тогда максимумы будут вычисляться не по
столбцам, а по строкам. Прибавьте 1 к массиву, который вернёт функция np.argmax, так как
распознаваемые цифры смещены относительно индексов в массиве на 1 (см. рисунок выше). Верните из
функции итоговый массив с результатами предсказания.
6. Оценить точность распознавания
В файле run.py дополнить код так, чтобы оценивалось качество распознавания. Под качеством
понимается отношение верно распознанных цифр к общему размеру выборки, умноженное на 100%.Чтобы выполнить задание, необходимо сначала для тестовой выборки получить результат предсказания
нейросети, а затем сравнить его с исходными фактическими значениями из выборки. Для получения
предсказания нейросети используйте код:
pred = predict(Theta1, Theta2, X)
predict – это функция, которую вы модифицировали в задании 5. Theta1 и Theta2 – весовые
коэффициенты обученной нейросети, которые вы ранее загрузили. X – матрица тестовых примеров.
Затем необходимо сравнить результаты предсказания сети с реальными значениями. Чтобы сравнить
массив pred со значениями вектора-столбца y, необходимо сначала y преобразовать к одномерному
массиву. Для этого используйте метод y.ravel(). Сравнение выполняется оператором ==. Результат
выполнения данного оператора – массив значений True и False. Чтобы оценить точность, нужно
привести значения к типу double, передав результат сравнения в функцию np.double(), а затем
посчитать среднее количество совпавших значений, которое можно вычислить функцией np.mean.
Если вы всё сделали правильно, должно получиться значение точности около 97.5%.
7. Продемонстрировать классификацию для 5 случайных примеров
Используйте приведённый ниже код, чтобы выполнить предсказание для 5 случайных примеров из
обучающей выборки:
rp = np.random.permutation(m)
plt.figure()
for i in range(5):
X2 = X[rp[i],:]
X2 = np.matrix(X[rp[i]])
pred = predict(Theta1, Theta2, X2.getA())
pred = np.squeeze(pred)
pred_str = 'Neural Network Prediction: %d (digit %d)' % (pred, y[rp[i]])
displayData(X2, pred_str)
plt.close()
8. Вывести примеры, на которых нейронная сеть ошиблась
Выполните предсказание цифр как в задании 6. С помощью функции np.where определите индексы
примеров, на которых нейросеть ошиблась. Параметром в функцию передаётся условие pred !=
y.ravel(). Функция np.where возвращает кортеж, в котором нас интересует только первое значение,
поэтому используйте код np.where(pred != y.ravel())[0], чтобы получить индексы примеров, на
которых нейронная сеть сработала неверно.
Возьмите первые 100 примеров, а затем отобразите их функцией displayData. Если вы всё сделали
верно, должна отобразиться приметно такая картинка:
